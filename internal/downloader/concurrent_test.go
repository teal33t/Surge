package downloader

import (
	"context"
	"path/filepath"
	"sync/atomic"
	"testing"
	"time"

	"surge/internal/config"
	"surge/internal/testutil"
)

// =============================================================================
// createTasks Tests
// =============================================================================

func TestCreateTasks_Basic(t *testing.T) {
	fileSize := int64(1024 * 1024) // 1MB
	chunkSize := int64(256 * 1024) // 256KB

	tasks := createTasks(fileSize, chunkSize)

	if len(tasks) != 4 {
		t.Errorf("Expected 4 tasks, got %d", len(tasks))
	}

	// Verify tasks cover the entire file
	var totalLength int64
	for i, task := range tasks {
		totalLength += task.Length
		expectedOffset := int64(i) * chunkSize
		if task.Offset != expectedOffset {
			t.Errorf("Task %d: got offset %d, want %d", i, task.Offset, expectedOffset)
		}
	}

	if totalLength != fileSize {
		t.Errorf("Total length %d doesn't cover file size %d", totalLength, fileSize)
	}
}

func TestCreateTasks_UnevenDivision(t *testing.T) {
	fileSize := int64(1000)
	chunkSize := int64(300)

	tasks := createTasks(fileSize, chunkSize)

	if len(tasks) != 4 {
		t.Errorf("Expected 4 tasks, got %d", len(tasks))
	}

	lastTask := tasks[len(tasks)-1]
	if lastTask.Length != 100 {
		t.Errorf("Last task length should be 100, got %d", lastTask.Length)
	}
}

func TestCreateTasks_SmallFile(t *testing.T) {
	fileSize := int64(100)
	chunkSize := int64(1024)

	tasks := createTasks(fileSize, chunkSize)

	if len(tasks) != 1 {
		t.Errorf("Small file should have 1 task, got %d", len(tasks))
	}
	if tasks[0].Length != 100 {
		t.Errorf("Task length should equal file size, got %d", tasks[0].Length)
	}
}

func TestCreateTasks_ExactDivision(t *testing.T) {
	fileSize := int64(4096)
	chunkSize := int64(1024)

	tasks := createTasks(fileSize, chunkSize)

	if len(tasks) != 4 {
		t.Errorf("Expected 4 tasks, got %d", len(tasks))
	}

	for _, task := range tasks {
		if task.Length != 1024 {
			t.Errorf("Each task should be 1024 bytes, got %d", task.Length)
		}
	}
}

func TestCreateTasks_ZeroChunkSize(t *testing.T) {
	tasks := createTasks(1000, 0)
	if tasks != nil {
		t.Error("createTasks should return nil for zero chunk size")
	}

	tasks = createTasks(1000, -1)
	if tasks != nil {
		t.Error("createTasks should return nil for negative chunk size")
	}
}

// =============================================================================
// ConcurrentDownloader Tests with Mock Server
// =============================================================================

func TestConcurrentDownloader_SmallFile(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(64 * 1024) // 64KB
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
		testutil.WithFilename("small_test.bin"),
	)
	defer server.Close()

	tmpDir, cleanup, err := testutil.TempDir("surge-download-test")
	if err != nil {
		t.Fatal(err)
	}
	defer cleanup()

	destPath := filepath.Join(tmpDir, "small_test.bin")
	state := NewProgressState("test-download", fileSize)
	runtime := &RuntimeConfig{
		MaxConnectionsPerHost: 4,
		MinChunkSize:          16 * KB,
		MaxChunkSize:          32 * KB,
		TargetChunkSize:       16 * KB,
		WorkerBufferSize:      8 * KB,
		MaxTaskRetries:        3,
	}

	downloader := NewConcurrentDownloader("test-id", nil, state, runtime)

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	err = downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	if err != nil {
		t.Fatalf("Download failed: %v", err)
	}

	if err := testutil.VerifyFileSize(destPath, fileSize); err != nil {
		t.Error(err)
	}

	surgeFile := destPath + IncompleteSuffix
	if testutil.FileExists(surgeFile) {
		t.Error(".surge file should be removed after successful download")
	}
}

func TestConcurrentDownloader_MediumFile(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(1 * MB)
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-download-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "medium_test.bin")
	state := NewProgressState("test-download", fileSize)
	runtime := &RuntimeConfig{
		MaxConnectionsPerHost: 8,
		MinChunkSize:          64 * KB,
		MaxChunkSize:          256 * KB,
		TargetChunkSize:       128 * KB,
		WorkerBufferSize:      32 * KB,
		MaxTaskRetries:        3,
	}

	downloader := NewConcurrentDownloader("test-id", nil, state, runtime)

	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	err := downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	if err != nil {
		t.Fatalf("Download failed: %v", err)
	}

	if err := testutil.VerifyFileSize(destPath, fileSize); err != nil {
		t.Error(err)
	}

	stats := server.Stats()
	if stats.RangeRequests == 0 {
		t.Error("Expected range requests for concurrent download")
	}
}

func TestConcurrentDownloader_Cancellation(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(10 * MB)
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
		testutil.WithByteLatency(100*time.Microsecond),
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-cancel-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "cancel_test.bin")
	state := NewProgressState("cancel-test", fileSize)
	runtime := &RuntimeConfig{MaxConnectionsPerHost: 4}

	downloader := NewConcurrentDownloader("cancel-id", nil, state, runtime)

	ctx, cancel := context.WithCancel(context.Background())

	done := make(chan error)
	go func() {
		done <- downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	}()

	time.Sleep(200 * time.Millisecond)
	cancel()

	select {
	case err := <-done:
		if err != nil && err != context.Canceled {
			t.Logf("Download returned: %v (expected context.Canceled or nil)", err)
		}
	case <-time.After(5 * time.Second):
		t.Fatal("Download didn't respond to cancellation")
	}
}

func TestConcurrentDownloader_ProgressTracking(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(512 * KB)
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-progress-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "progress_test.bin")
	state := NewProgressState("progress-test", fileSize)
	runtime := &RuntimeConfig{MaxConnectionsPerHost: 4}

	downloader := NewConcurrentDownloader("progress-id", nil, state, runtime)

	var maxProgress int64
	var progressUpdates int64
	stopMonitor := make(chan struct{})

	go func() {
		ticker := time.NewTicker(10 * time.Millisecond)
		defer ticker.Stop()
		for {
			select {
			case <-stopMonitor:
				return
			case <-ticker.C:
				current := state.Downloaded.Load()
				if current > maxProgress {
					maxProgress = current
					atomic.AddInt64(&progressUpdates, 1)
				}
			}
		}
	}()

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	err := downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	close(stopMonitor)

	if err != nil {
		t.Fatalf("Download failed: %v", err)
	}

	if atomic.LoadInt64(&progressUpdates) == 0 {
		t.Error("Expected to see progress updates during download")
	}

	finalDownloaded := state.Downloaded.Load()
	if finalDownloaded != fileSize {
		t.Errorf("Final downloaded %d != file size %d", finalDownloaded, fileSize)
	}
}

// =============================================================================
// Advanced Integration Tests - Retry Logic
// =============================================================================

func TestConcurrentDownloader_RetryOnFailure(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(256 * KB)
	// Server fails after 20KB per-request, forcing retries
	// With 64KB chunks, each request will fail mid-way
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
		testutil.WithFailAfterBytes(20*KB), // Fail after 20KB per request
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-retry-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "retry_test.bin")
	state := NewProgressState("retry-test", fileSize)
	runtime := &RuntimeConfig{
		MaxConnectionsPerHost: 2,
		MaxTaskRetries:        10,      // Need more retries since each attempt only gets 20KB
		MinChunkSize:          64 * KB, // Larger chunks to ensure failures occur
		MaxChunkSize:          64 * KB,
		TargetChunkSize:       64 * KB,
	}

	downloader := NewConcurrentDownloader("retry-id", nil, state, runtime)

	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	err := downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	if err != nil {
		t.Fatalf("Download with retries failed: %v", err)
	}

	if err := testutil.VerifyFileSize(destPath, fileSize); err != nil {
		t.Error(err)
	}

	stats := server.Stats()
	if stats.FailedRequests == 0 {
		t.Error("Expected some failed requests that triggered retries")
	}
}

func TestConcurrentDownloader_FailOnNthRequest(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(256 * KB)
	// Fail the 2nd request - use 1 connection for predictable ordering
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
		testutil.WithFailOnNthRequest(2),
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-failnth-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "failnth_test.bin")
	state := NewProgressState("failnth-test", fileSize)
	runtime := &RuntimeConfig{
		MaxConnectionsPerHost: 1, // Single connection for predictable request order
		MaxTaskRetries:        5,
		MinChunkSize:          64 * KB, // 4 chunks = 4 requests minimum
	}

	downloader := NewConcurrentDownloader("failnth-id", nil, state, runtime)

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	err := downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	if err != nil {
		t.Fatalf("Download should recover from Nth request failure: %v", err)
	}

	stats := server.Stats()
	if stats.FailedRequests < 1 {
		t.Errorf("Expected at least 1 failed request, got %d", stats.FailedRequests)
	}
	t.Logf("Stats: TotalRequests=%d, FailedRequests=%d", stats.TotalRequests, stats.FailedRequests)
}

// =============================================================================
// Advanced Integration Tests - Latency & Timeouts
// =============================================================================

func TestConcurrentDownloader_WithLatency(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(64 * KB)
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
		testutil.WithLatency(100*time.Millisecond), // 100ms per request
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-latency-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "latency_test.bin")
	state := NewProgressState("latency-test", fileSize)
	runtime := &RuntimeConfig{MaxConnectionsPerHost: 2}

	downloader := NewConcurrentDownloader("latency-id", nil, state, runtime)

	start := time.Now()
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	err := downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	elapsed := time.Since(start)

	if err != nil {
		t.Fatalf("Download failed: %v", err)
	}

	// Should take at least 100ms due to latency
	if elapsed < 100*time.Millisecond {
		t.Errorf("Download completed too fast (%v), latency not applied", elapsed)
	}

	if err := testutil.VerifyFileSize(destPath, fileSize); err != nil {
		t.Error(err)
	}
}

func TestConcurrentDownloader_SlowDownload(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(32 * KB)
	// Very slow byte-by-byte latency
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
		testutil.WithByteLatency(10*time.Microsecond),
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-slow-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "slow_test.bin")
	state := NewProgressState("slow-test", fileSize)
	runtime := &RuntimeConfig{MaxConnectionsPerHost: 4}

	downloader := NewConcurrentDownloader("slow-id", nil, state, runtime)

	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	err := downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	if err != nil {
		t.Fatalf("Slow download failed: %v", err)
	}

	if err := testutil.VerifyFileSize(destPath, fileSize); err != nil {
		t.Error(err)
	}
}

// =============================================================================
// Advanced Integration Tests - Connection Limits
// =============================================================================

func TestConcurrentDownloader_RespectServerConnectionLimit(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(256 * KB)
	maxConns := 2
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
		testutil.WithMaxConcurrentRequests(maxConns),
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-connlimit-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "connlimit_test.bin")
	state := NewProgressState("connlimit-test", fileSize)
	// Client configured for more connections than server allows
	runtime := &RuntimeConfig{
		MaxConnectionsPerHost: 8, // More than server allows
		MinChunkSize:          16 * KB,
	}

	downloader := NewConcurrentDownloader("connlimit-id", nil, state, runtime)

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	err := downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	if err != nil {
		t.Fatalf("Download failed: %v", err)
	}

	if err := testutil.VerifyFileSize(destPath, fileSize); err != nil {
		t.Error(err)
	}

	stats := server.Stats()
	t.Logf("Server stats: TotalRequests=%d, RangeRequests=%d", stats.TotalRequests, stats.RangeRequests)
}

// =============================================================================
// Advanced Integration Tests - Content Verification
// =============================================================================

func TestConcurrentDownloader_ContentIntegrity(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(128 * KB)
	// Use random data so we can verify content integrity
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
		testutil.WithRandomData(true),
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-integrity-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "integrity_test.bin")
	state := NewProgressState("integrity-test", fileSize)
	runtime := &RuntimeConfig{
		MaxConnectionsPerHost: 4,
		MinChunkSize:          16 * KB,
	}

	downloader := NewConcurrentDownloader("integrity-id", nil, state, runtime)

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	err := downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	if err != nil {
		t.Fatalf("Download failed: %v", err)
	}

	// Verify file size matches
	if err := testutil.VerifyFileSize(destPath, fileSize); err != nil {
		t.Error(err)
	}

	// Read first and last chunks and verify they're not all zeros
	first, err := testutil.ReadFileChunk(destPath, 0, 1024)
	if err != nil {
		t.Fatal(err)
	}
	last, err := testutil.ReadFileChunk(destPath, fileSize-1024, 1024)
	if err != nil {
		t.Fatal(err)
	}

	// Random data shouldn't be all zeros
	allZero := true
	for _, b := range first {
		if b != 0 {
			allZero = false
			break
		}
	}
	if allZero {
		t.Error("First chunk is all zeros - random data not applied correctly")
	}

	allZero = true
	for _, b := range last {
		if b != 0 {
			allZero = false
			break
		}
	}
	if allZero {
		t.Error("Last chunk is all zeros - random data not applied correctly")
	}
}

// =============================================================================
// Advanced Integration Tests - Resume from Partial Download
// =============================================================================

func TestConcurrentDownloader_ResumePartialDownload(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	fileSize := int64(256 * KB)
	server := testutil.NewMockServer(
		testutil.WithFileSize(fileSize),
		testutil.WithRangeSupport(true),
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-resume-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "resume_test.bin")
	workingPath := destPath + IncompleteSuffix

	// Create partial .surge file (simulate interrupted download)
	partialSize := int64(100 * KB)
	_, err := testutil.CreateTestFile(tmpDir, "resume_test.bin.surge", partialSize, false)
	if err != nil {
		t.Fatal(err)
	}

	// Create saved state for resume
	remainingTasks := []Task{
		{Offset: partialSize, Length: fileSize - partialSize},
	}
	savedState := &DownloadState{
		URL:        server.URL(),
		DestPath:   destPath,
		TotalSize:  fileSize,
		Downloaded: partialSize,
		Tasks:      remainingTasks,
		Filename:   "resume_test.bin",
	}
	if err := SaveState(server.URL(), destPath, savedState); err != nil {
		t.Fatalf("Failed to save state: %v", err)
	}
	defer DeleteState(server.URL(), destPath)

	// Now resume download
	state := NewProgressState("resume-test", fileSize)
	runtime := &RuntimeConfig{MaxConnectionsPerHost: 2}

	downloader := NewConcurrentDownloader("resume-id", nil, state, runtime)

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	err = downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	if err != nil {
		t.Fatalf("Resume download failed: %v", err)
	}

	// Verify final file exists (not .surge)
	if testutil.FileExists(workingPath) {
		t.Error(".surge file should be removed after completion")
	}

	if err := testutil.VerifyFileSize(destPath, fileSize); err != nil {
		t.Error(err)
	}

	// State file should be deleted on success
	_, err = LoadState(server.URL(), destPath)
	if err == nil {
		t.Error("State file should be deleted after successful download")
	}
}

// =============================================================================
// getInitialConnections Tests
// =============================================================================

func TestGetInitialConnections(t *testing.T) {
	runtime := &RuntimeConfig{MaxConnectionsPerHost: 64}
	downloader := NewConcurrentDownloader("test", nil, nil, runtime)

	tests := []struct {
		fileSize      int64
		expectedConns int
	}{
		{5 * MB, 1},   // <10MB = 1 connection
		{50 * MB, 4},  // 10-100MB = 4 connections
		{500 * MB, 6}, // 100MB-1GB = 6 connections
		{2 * GB, 32},  // >1GB = 32 connections
	}

	for _, tt := range tests {
		conns := downloader.getInitialConnections(tt.fileSize)
		if conns != tt.expectedConns {
			t.Errorf("getInitialConnections(%d) = %d, want %d",
				tt.fileSize, conns, tt.expectedConns)
		}
	}
}

func TestGetInitialConnections_RespectMaxConns(t *testing.T) {
	runtime := &RuntimeConfig{MaxConnectionsPerHost: 4}
	downloader := NewConcurrentDownloader("test", nil, nil, runtime)

	conns := downloader.getInitialConnections(2 * GB)
	if conns != 4 {
		t.Errorf("Should respect max connections, got %d", conns)
	}
}

// =============================================================================
// calculateChunkSize Tests
// =============================================================================

func TestCalculateChunkSize(t *testing.T) {
	runtime := &RuntimeConfig{
		MinChunkSize:    1 * MB,
		MaxChunkSize:    16 * MB,
		TargetChunkSize: 8 * MB,
	}
	downloader := NewConcurrentDownloader("test", nil, nil, runtime)

	chunkSize := downloader.calculateChunkSize(100*MB, 4)

	if chunkSize < 1*MB {
		t.Errorf("Chunk size %d below minimum", chunkSize)
	}
	if chunkSize > 16*MB {
		t.Errorf("Chunk size %d above maximum", chunkSize)
	}
	if chunkSize%AlignSize != 0 {
		t.Errorf("Chunk size %d not aligned to %d", chunkSize, AlignSize)
	}
}

func TestCalculateChunkSize_SmallFile(t *testing.T) {
	runtime := &RuntimeConfig{
		MinChunkSize:    1 * MB,
		MaxChunkSize:    16 * MB,
		TargetChunkSize: 8 * MB,
	}
	downloader := NewConcurrentDownloader("test", nil, nil, runtime)

	chunkSize := downloader.calculateChunkSize(100*KB, 4)

	if chunkSize < AlignSize {
		t.Error("Chunk size too small")
	}
}

// =============================================================================
// NewConcurrentDownloader Tests
// =============================================================================

func TestNewConcurrentDownloader(t *testing.T) {
	state := NewProgressState("test", 1000)
	runtime := &RuntimeConfig{MaxConnectionsPerHost: 8}

	downloader := NewConcurrentDownloader("test-id", nil, state, runtime)

	if downloader == nil {
		t.Fatal("NewConcurrentDownloader returned nil")
	}
	if downloader.ID != "test-id" {
		t.Errorf("ID mismatch: got %s", downloader.ID)
	}
	if downloader.State != state {
		t.Error("State not set correctly")
	}
	if downloader.Runtime != runtime {
		t.Error("Runtime not set correctly")
	}
}

func TestNewConcurrentDownloader_NilState(t *testing.T) {
	runtime := &RuntimeConfig{}
	downloader := NewConcurrentDownloader("test-id", nil, nil, runtime)

	if downloader == nil {
		t.Fatal("Should handle nil state")
	}
}

func TestNewConcurrentDownloader_NilRuntime(t *testing.T) {
	state := NewProgressState("test", 1000)
	downloader := NewConcurrentDownloader("test-id", nil, state, nil)

	if downloader == nil {
		t.Fatal("Should handle nil runtime")
	}
}

// =============================================================================
// IncompleteSuffix Tests
// =============================================================================

func TestIncompleteSuffix(t *testing.T) {
	if IncompleteSuffix != ".surge" {
		t.Errorf("IncompleteSuffix = %q, want .surge", IncompleteSuffix)
	}
}

// =============================================================================
// Buffer Pool Tests
// =============================================================================

func TestBufPool(t *testing.T) {
	bufPtr := bufPool.Get().(*[]byte)
	if bufPtr == nil {
		t.Fatal("bufPool.Get() returned nil")
	}

	buf := *bufPtr
	if len(buf) != WorkerBuffer {
		t.Errorf("Buffer size = %d, want %d", len(buf), WorkerBuffer)
	}

	bufPool.Put(bufPtr)

	bufPtr2 := bufPool.Get().(*[]byte)
	if bufPtr2 == nil {
		t.Fatal("bufPool.Get() returned nil after Put")
	}
}

// =============================================================================
// Streaming Mock Server Tests (Large Files)
// =============================================================================

func TestConcurrentDownloader_StreamingServer(t *testing.T) {
	if err := config.EnsureDirs(); err != nil {
		t.Fatalf("Failed to create config dirs: %v", err)
	}

	// Use streaming server for larger files without memory allocation
	fileSize := int64(2 * MB)
	server := testutil.NewStreamingMockServer(fileSize,
		testutil.WithRangeSupport(true),
	)
	defer server.Close()

	tmpDir, cleanup, _ := testutil.TempDir("surge-stream-test")
	defer cleanup()

	destPath := filepath.Join(tmpDir, "stream_test.bin")
	state := NewProgressState("stream-test", fileSize)
	runtime := &RuntimeConfig{
		MaxConnectionsPerHost: 4,
		MinChunkSize:          256 * KB,
	}

	downloader := NewConcurrentDownloader("stream-id", nil, state, runtime)

	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	err := downloader.Download(ctx, server.URL(), destPath, fileSize, false)
	if err != nil {
		t.Fatalf("Streaming download failed: %v", err)
	}

	if err := testutil.VerifyFileSize(destPath, fileSize); err != nil {
		t.Error(err)
	}
}
